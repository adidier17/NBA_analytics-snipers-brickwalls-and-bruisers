setwd('/Users/ethen/northwestern/russ')#
data <- read.csv("rmarkdown sample data.csv", header = T, sep =",")#
#data <- WTCPoliceCalls#
# rename columns#
names(data)[1] <- "date"#
names(data)[2] <- "sender_id"#
names(data)[3] <- "recipient_id"#
#
# select subsample to save time#
#data <- data[1:100,] #
#
data$sender_id <- tolower(data[,2])#
data$recipient_id <- tolower(data[,3])#
N <- nrow(data)#
data$T_ID<- c(1:N)#
#
#column is_active == 1#
is_active <- rep(1, N)#
data$is_active <- is_active#
data$sender_id <- tolower(data[,2])#
data$recipient_id <- tolower(data[,3])#
ties <- nrow(data) # number of ties#
data$number<- c(1:ties)#
#
names <- unique(c(data$sender_id, data$recipient_id)) # get names of each individual#
numeric_ids <- data.frame(number = c(1:length(names)),name = names) # create data frame in order to give each individual a numeric id#
nodes <- length(names) # number of nodes#
numeric_ids$sender_idnum <- row(numeric_ids[2])#
numeric_ids$recipient_idnum <- row(numeric_ids[2])#
#
edgelist <- data.frame(number = c(1:nrow(data)))#
edgelist$sender_idnum<-numeric_ids$sender_idnum[match(data$sender_id,numeric_ids$name)]#
edgelist$recipient_idnum<-numeric_ids$recipient_idnum[match(data$recipient_id,numeric_ids$name)]#
eventlist <- as.sociomatrix.eventlist(edgelist,nodes) # create an eventlist for sna#
# descriptives#
#degree#
totaldegree <-degree(eventlist) # Default: total degree#
ideg <- degree(eventlist, cmode="indegree") # Indegree #
odeg <- degree(eventlist, cmode="outdegree") # Outdegree #
#
#Plot the degree:#
plot(ideg, odeg, type="n", xlab="Incoming Messages", ylab="Outgoing Messages") # Plot ideg by odeg#
abline(0, 1, lty=3)#
#
#Plot simple histograms of the degree distribution:#
#par(mfrow=c(2,2)) # Set up a 2x2 display#
hist(ideg, xlab="Indegree", main="Indegree Distribution", prob=TRUE)#
hist(odeg, xlab="Outdegree", main="Outdegree Distribution", prob=TRUE)#
hist(ideg+odeg, xlab="Total Degree", main="Total Degree Distribution", prob=TRUE)#
#par(mfrow=c(1,1)) # Restore display#
#
gplot(eventlist,edge.lwd=eventlist^0.75,vertex.col=2,vertex.cex=1.25)
library(foreach) #for creating dataset and variables#
library(doParallel)#
library(survival) #for fitting models#
library(stargazer) #for tables#
library(car) #for vif#
library(Hmisc) #for rcorr#
library(arm) # for coefplot#
setwd('/Users/ethen/northwestern/russ')#
data <- read.csv("rmarkdown sample data.csv", header = T, sep =",")#
#data <- WTCPoliceCalls#
# rename columns#
names(data)[1] <- "date"#
names(data)[2] <- "sender_id"#
names(data)[3] <- "recipient_id"#
#
# select subsample to save time#
#data <- data[1:100,] #
#
data$sender_id <- tolower(data[,2])#
data$recipient_id <- tolower(data[,3])#
N <- nrow(data)#
data$T_ID<- c(1:N)#
#
#column is_active == 1#
is_active <- rep(1, N)#
data$is_active <- is_active#
data$sender_id <- tolower(data[,2])#
data$recipient_id <- tolower(data[,3])#
ties <- nrow(data) # number of ties#
data$number<- c(1:ties)#
#
names <- unique(c(data$sender_id, data$recipient_id)) # get names of each individual#
numeric_ids <- data.frame(number = c(1:length(names)),name = names) # create data frame in order to give each individual a numeric id#
nodes <- length(names) # number of nodes#
numeric_ids$sender_idnum <- row(numeric_ids[2])#
numeric_ids$recipient_idnum <- row(numeric_ids[2])#
#
edgelist <- data.frame(number = c(1:nrow(data)))#
edgelist$sender_idnum<-numeric_ids$sender_idnum[match(data$sender_id,numeric_ids$name)]#
edgelist$recipient_idnum<-numeric_ids$recipient_idnum[match(data$recipient_id,numeric_ids$name)]#
eventlist <- as.sociomatrix.eventlist(edgelist,nodes) # create an eventlist for sna#
# descriptives#
#degree#
totaldegree <-degree(eventlist) # Default: total degree#
ideg <- degree(eventlist, cmode="indegree") # Indegree #
odeg <- degree(eventlist, cmode="outdegree") # Outdegree #
#
#Plot the degree:#
plot(ideg, odeg, type="n", xlab="Incoming Messages", ylab="Outgoing Messages") # Plot ideg by odeg#
abline(0, 1, lty=3)#
#
#Plot simple histograms of the degree distribution:#
#par(mfrow=c(2,2)) # Set up a 2x2 display#
hist(ideg, xlab="Indegree", main="Indegree Distribution", prob=TRUE)#
hist(odeg, xlab="Outdegree", main="Outdegree Distribution", prob=TRUE)#
hist(ideg+odeg, xlab="Total Degree", main="Total Degree Distribution", prob=TRUE)#
#par(mfrow=c(1,1)) # Restore display#
#
gplot(eventlist,edge.lwd=eventlist^0.75,vertex.col=2,vertex.cex=1.25)
data <- read.csv("rmarkdown sample data.csv", header = T, sep =",")#
#data <- WTCPoliceCalls#
# rename columns#
names(data)[1] <- "date"#
names(data)[2] <- "sender_id"#
names(data)[3] <- "recipient_id"#
#
# select subsample to save time#
#data <- data[1:100,] #
#
data$sender_id <- tolower(data[,2])#
data$recipient_id <- tolower(data[,3])#
N <- nrow(data)#
data$T_ID<- c(1:N)#
#
#column is_active == 1#
is_active <- rep(1, N)#
data$is_active <- is_active#
data$sender_id <- tolower(data[,2])#
data$recipient_id <- tolower(data[,3])#
ties <- nrow(data) # number of ties#
data$number<- c(1:ties)#
#
names <- unique(c(data$sender_id, data$recipient_id)) # get names of each individual#
numeric_ids <- data.frame(number = c(1:length(names)),name = names) # create data frame in order to give each individual a numeric id#
nodes <- length(names) # number of nodes#
numeric_ids$sender_idnum <- row(numeric_ids[2])#
numeric_ids$recipient_idnum <- row(numeric_ids[2])#
#
edgelist <- data.frame(number = c(1:nrow(data)))#
edgelist$sender_idnum<-numeric_ids$sender_idnum[match(data$sender_id,numeric_ids$name)]#
edgelist$recipient_idnum<-numeric_ids$recipient_idnum[match(data$recipient_id,numeric_ids$name)]
library(ggplot2)#
library(ggthemes)#
library(data.table)#
library(doParallel)#
#
compute_normal_loglike <- function(value, cutoff) {#
    # compute log-likelihood ratio, R, #
    # across all possible time tau#
#
    # null hypothesis H0#
    loss_h0 <- sum( (value - mean(value)) ^ 2 )#
#
    # alternative hypothesis for all possible time#
    N <- length(value) - 2 * cutoff#
    registerDoParallel(cores = detectCores())#
    loss_h1 <- foreach(i = icount(N), .combine = c) %dopar% {#
        before <- value[1:(i + cutoff)]#
        after  <- value[(i + cutoff + 1):length(value)]#
        loss_before <- sum( (before - mean(before)) ^ 2 )#
        loss_after  <- sum( (after - mean(after)) ^ 2 )#
        loss_total  <- loss_before + loss_after#
        return(loss_total)#
    }#
    stopImplicitCluster()#
    R <- -1 / (2 * var(value)) * (loss_h1 - loss_h0)#
    return(R)   #
}#
#
plot_changepoint <- function(value, cutoff, threshold, R) {#
    dt_data <- data.table(time = 1:length(value), value = value)#
    plot <- ggplot( dt_data, aes(time, value) ) +#
            geom_line(color = '#008FD5') +#
            theme_fivethirtyeight()#
#
    # test whether there's is changepoint#
    upper_quantile <- quantile(R, 0.75)#
    criterion <- threshold * upper_quantile#
    G <- max(R)#
    if (G > criterion) {#
        changepoint <- which.max(R) + cutoff#
        mean_before <- mean(value[1:changepoint])#
        mean_after  <- mean(value[(changepoint + 1):length(value)])#
        # add changepoint information to the plot#
        title <- sprintf('changepoint detected at time %d, #
                          previous mean %.1f, new mean %.1f', changepoint, mean1, mean2)#
        plot <- plot +#
                geom_segment( aes(x = 1, xend = changepoint, #
                                  y = mean_before, yend = mean_before),#
                              color = '#FF2700' ) +#
                geom_segment( aes(x = changepoint + 1, xend = nrow(dt_data), #
                                  y = mean_after, yend = mean_after),#
                              color = '#FF2700' ) +#
                geom_vline(xintercept = changepoint, color = '#FF2700', linetype = 'dashed')#
    } else {#
        mean_overall <- mean(value)#
        title <- sprintf('mean %.1f', mean_overall)#
        plot <- plot + #
                geom_segment( aes(x = 1, xend = nrow(dt_data), y = mean, yend = mean),#
                              color = '#FF2700' )#
    }#
    plot <- plot + labs(title = title)#
    return(plot)#
}
library(ggplot2)#
library(ggthemes)#
library(data.table)#
library(doParallel)#
#
compute_normal_loglike <- function(value, cutoff) {#
    # compute log-likelihood ratio, R, #
    # across all possible time tau#
#
    # null hypothesis H0#
    loss_h0 <- sum( (value - mean(value)) ^ 2 )#
#
    # alternative hypothesis for all possible time#
    N <- length(value) - 2 * cutoff#
    registerDoParallel(cores = detectCores())#
    loss_h1 <- foreach(i = icount(N), .combine = c) %dopar% {#
        before <- value[1:(i + cutoff)]#
        after  <- value[(i + cutoff + 1):length(value)]#
        loss_before <- sum( (before - mean(before)) ^ 2 )#
        loss_after  <- sum( (after - mean(after)) ^ 2 )#
        loss_total  <- loss_before + loss_after#
        return(loss_total)#
    }#
    stopImplicitCluster()#
    R <- -1 / (2 * var(value)) * (loss_h1 - loss_h0)#
    return(R)   #
}#
#
plot_changepoint <- function(value, cutoff, threshold, R) {#
    dt_data <- data.table(time = 1:length(value), value = value)#
    plot <- ggplot( dt_data, aes(time, value) ) +#
            geom_line(color = '#008FD5') +#
            theme_fivethirtyeight()#
#
    # test whether there's is changepoint#
    upper_quantile <- quantile(R, 0.75)#
    criterion <- threshold * upper_quantile#
    G <- max(R)#
    if (G > criterion) {#
        changepoint <- which.max(R) + cutoff#
        mean_before <- mean(value[1:changepoint])#
        mean_after  <- mean(value[(changepoint + 1):length(value)])#
        # add changepoint information to the plot#
        title <- sprintf('changepoint detected at time %d, #
                          previous mean %.1f, new mean %.1f', #
                          changepoint, mean_before, mean_after)#
        plot <- plot +#
                geom_segment( aes(x = 1, xend = changepoint, #
                                  y = mean_before, yend = mean_before),#
                              color = '#FF2700' ) +#
                geom_segment( aes(x = changepoint + 1, xend = nrow(dt_data), #
                                  y = mean_after, yend = mean_after),#
                              color = '#FF2700' ) +#
                geom_vline(xintercept = changepoint, color = '#FF2700', linetype = 'dashed')#
    } else {#
        mean_overall <- mean(value)#
        title <- sprintf('mean %.1f', mean_overall)#
        plot <- plot + #
                geom_segment( aes(x = 1, xend = nrow(dt_data), y = mean, yend = mean),#
                              color = '#FF2700' )#
    }#
    plot <- plot + labs(title = title)#
    return(plot)#
}
library(myFirstPackage)
sessionInfo()
compute_root_square(4)
library(myFirstPackage)#
compute_square_root(4)
myFirstPackage::compute_square_root(4)
myFirstPackage::compute_square_root
generated_sales_data <- round( rlnorm(10000, mean = 3.21, sd = 0.6), 2 )
generated_sales_data
p <- ggplot(sales, aes(x=purchase_amount)) + #
     geom_histogram(binwidth=.5) + #
     xlim(0, 150) + #
     xlab("Customer amount spent (in $)") +#
     ylab("# of customers") + #
     ggtitle("Amounts spent by individual consumers") + #
     theme(axis.title.y = element_text(angle = 0))#
print(p)
library(ggplot2)#
generated_sales_data <- round( rlnorm(10000, mean = 3.21, sd = 0.6), 2 )#
#
p <- ggplot(sales, aes(x=purchase_amount)) + #
     geom_histogram(binwidth=.5) + #
     xlim(0, 150) + #
     xlab("Customer amount spent (in $)") +#
     ylab("# of customers") + #
     ggtitle("Amounts spent by individual consumers") + #
     theme(axis.title.y = element_text(angle = 0))#
print(p)
library(ggplot2)#
sales <- round( rlnorm(10000, mean = 3.21, sd = 0.6), 2 )#
#
p <- ggplot(sales, aes(x=purchase_amount)) + #
     geom_histogram(binwidth=.5) + #
     xlim(0, 150) + #
     xlab("Customer amount spent (in $)") +#
     ylab("# of customers") + #
     ggtitle("Amounts spent by individual consumers") + #
     theme(axis.title.y = element_text(angle = 0))#
print(p)
library(ggplot2)#
library(data.table)#
sales <- data.table( purchase_amount = rlnorm(10000, mean = 3.21, sd = 0.6) )#
#
p <- ggplot(sales, aes(x = purchase_amount)) + #
     geom_histogram(binwidth=.5) + #
     xlim(0, 150) + #
     xlab("Customer amount spent (in $)") +#
     ylab("# of customers") + #
     ggtitle("Amounts spent by individual consumers") + #
     theme(axis.title.y = element_text(angle = 0))#
print(p)
sales
p <- ggplot(sales, aes(x = purchase_amount)) + #
     geom_histogram(binwidth = .5) + #
     xlim(0, 150) + #
     xlab('Customer amount spent (in $)') +#
     ylab('# of customers') + #
     ggtitle('Amounts spent by individual consumers')
print(p)
info <- with( sales, list( count = length(amount_spent), #
                           log_mean = mean(log(amount_spent)),#
                           log_sd = sd(log(amount_spent)) ) )
info <- with( sales, list( count = length(purchase_amount), #
                           log_mean = mean(log(purchase_amount)),#
                           log_sd = sd(log(purchase_amount)) ) )
info
simulated <- data.table( #
    purchase_amount = rlnorm(info$count, mean = info$log_mean, sd = info$log_sd)#
)
p <- ggplot( simulated, aes(x = purchase_amount) ) + #
     geom_histogram(binwidth = 0.5) + #
     xlim(0, 150) + #
     xlab('price') +#
     ylab('# of orders') + #
     ggtitle('Simulated price frequency from one day')#
print(p)
library(ggplot2)
library(ggplot2)#
#
timing <- data.frame(time = c(4.86, 2.81), package = c('qmf', 'our own implementation'))
timing <- data.frame(time = c(4.86, 2.81), package = c('qmf', 'our own implementation'))#
#
ggplot(timing, aes(time, color = package)) +#
geom_count()
ggplot(timing, aes(time, color = package)) +#
geom_bar()
ggplot(timing, aes(time, fill = package)) +#
geom_bar()
ggplot(timing, aes(time, fill = package)) +#
geom_bar(stat = 'identity')
timing <- data.frame(#
    dataset = c('Last.fm', 'Last.fm', 'Amazon Product', 'Amazon Product')#
    time = c(4.86, 2.81, 34.46, 1.22.20), #
    package = c('qmf', 'our own implementation', 'qmf', 'our own implementation')#
)#
#
ggplot(timing, aes(time, fill = package)) +#
geom_bar(stat = 'identity')
ggplot(timing, aes(dataset, time, fill = package)) +#
geom_bar(stat = 'identity')
timing <- data.frame(#
    dataset = c('Last.fm', 'Last.fm', 'Amazon Product', 'Amazon Product'),#
    time = c(4.86, 2.81, 34.46, 1.22.20), #
    package = c('qmf', 'our own implementation', 'qmf', 'our own implementation')#
)#
#
ggplot(timing, aes(dataset, time, fill = package)) +#
geom_bar(stat = 'identity')
timing <- data.frame(#
    dataset = c('Last.fm', 'Last.fm', 'Amazon Product', 'Amazon Product'),#
    time = c(4.86, 2.81, 34.46, 1.22.20), #
    package = c('qmf', 'our own implementation', 'qmf', 'our own implementation')#
)#
#
ggplot(timing, aes(x = dataset, y = time, fill = package)) +#
geom_bar(stat = 'identity')
timing <- data.frame(#
    datasets = c('Last.fm', 'Last.fm', 'Amazon Product', 'Amazon Product'),#
    times = c(4.86, 2.81, 34.46, 1.22.20), #
    package = c('qmf', 'our own implementation', 'qmf', 'our own implementation')#
)#
#
ggplot(timing, aes(x = datasets, y = times, fill = package)) +#
geom_bar(stat = 'identity')
timing <- data.frame(#
    datasets = c('Last.fm', 'Last.fm', 'Amazon Product', 'Amazon Product'),#
    times = c(4.86, 2.81, 34.46, 82.20), #
    package = c('qmf', 'our own implementation', 'qmf', 'our own implementation')#
)
ggplot(timing, aes(x = datasets, y = times, fill = package)) +#
geom_bar(stat = 'identity')
ggplot(timing, aes(x = datasets, y = times, fill = package)) +#
geom_bar(stat = 'identity', position = 'dodge')
timing <- data.frame(#
    datasets = c('Last.fm', 'Last.fm', 'Amazon Product', 'Amazon Product'),#
    times = c(4.86, 2.81, 82.20, 34.46), #
    package = c('qmf', 'our own implementation', 'qmf', 'our own implementation')#
)#
#
ggplot(timing, aes(x = datasets, y = times, fill = package)) +#
geom_bar(stat = 'identity', position = 'dodge')
82.2 / 34.4
timing <- data.frame(#
    datasets = c('Last.fm', 'Last.fm', 'Amazon Product', 'Amazon Product'),#
    times = c(4.8, 2.8, 0.5, 82.2, 34.4, 6.5), #
    package = c('qmf', 'ours', 'ours on Allstate cluster', 'qmf', 'ours', 'ours on Allstate cluster')#
)#
#
ggplot(timing, aes(x = datasets, y = times, fill = package)) +#
geom_bar(stat = 'identity', position = 'dodge')
timing <- data.frame(#
    datasets = c('Last.fm', 'Last.fm', 'Last.fm', 'Amazon Product', 'Amazon Product', 'Amazon Product'),#
    times = c(4.8, 2.8, 0.5, 82.2, 34.4, 6.5), #
    package = c('qmf', 'ours', 'ours on Allstate cluster', 'qmf', 'ours', 'ours on Allstate cluster')#
)#
#
ggplot(timing, aes(x = datasets, y = times, fill = package)) +#
geom_bar(stat = 'identity', position = 'dodge')
?as.factor
timing <- data.table(#
    datasets = c('Last.fm', 'Last.fm', 'Last.fm', 'Amazon Product', 'Amazon Product', 'Amazon Product'),#
    times = c(4.8, 2.8, 0.5, 82.2, 34.4, 6.5), #
    package = c('qmf', 'ours', 'ours on Allstate cluster', 'qmf', 'ours', 'ours on Allstate cluster')#
)#
timing[ , package := as.factor(package, levels = c('qmf', 'ours', 'ours on Allstate cluster')) ]#
#
ggplot(timing, aes(x = datasets, y = times, fill = package)) +#
geom_bar(stat = 'identity', position = 'dodge')
ggplot(timing, aes(x = datasets, y = reorder(-times), fill = package)) +#
geom_bar(stat = 'identity', position = 'dodge')
ggplot(timing, aes(x = datasets, y = reordered(-times), fill = package)) +#
geom_bar(stat = 'identity', position = 'dodge')
ggplot(timing, aes(x = reorder(datasets, -times), y = times, fill = package)) +#
geom_bar(stat = 'identity', position = 'dodge')
df <- data.frame(b=1:10, c=c("z", "a"))#
ggplot(df, aes(x=1, y=b, fill=c)) + #
  geom_bar(stat="identity", position="dodge")
df$c <- factor(df$c, levels=c("z", "a"))#
ggplot(df, aes(x=1, y=b, fill=c)) + #
  geom_bar(stat="identity", position="dodge")
timing
sapply(timing, class)
library(ggplot2)#
library(data.table)#
#
timing <- data.table(#
    datasets = c('Last.fm', 'Last.fm', 'Last.fm', 'Amazon Product', 'Amazon Product', 'Amazon Product'),#
    times = c(4.8, 2.8, 0.5, 82.2, 34.4, 6.5), #
    package = c('qmf', 'ours', 'ours on Allstate cluster', 'qmf', 'ours', 'ours on Allstate cluster')#
)#
timing[ , package := as.factor(package, levels = c('qmf', 'ours', 'ours on Allstate cluster')) ]#
#
ggplot(timing, aes(x = reorder(datasets, -times), y = times, fill = package)) +#
geom_bar(stat = 'identity', position = 'dodge')
timing <- data.table(#
    datasets = c('Last.fm', 'Last.fm', 'Last.fm', 'Amazon Product', 'Amazon Product', 'Amazon Product'),#
    times = c(4.8, 2.8, 0.5, 82.2, 34.4, 6.5), #
    package = c('qmf', 'ours', 'ours on Allstate cluster', 'qmf', 'ours', 'ours on Allstate cluster')#
)#
timing[ , package := as.factor(package, levels = c('qmf', 'ours', 'ours on Allstate cluster')) ]#
#
ggplot(timing, aes(x = datasets, y = times, fill = package)) +#
geom_bar(stat = 'identity', position = 'dodge')
timing <- data.table(#
    datasets = c('Last.fm', 'Last.fm', 'Last.fm', 'Amazon Product', 'Amazon Product', 'Amazon Product'),#
    times = c(4.8, 2.8, 0.5, 82.2, 34.4, 6.5), #
    package = c('qmf', 'ours', 'ours on Allstate cluster', 'qmf', 'ours', 'ours on Allstate cluster')#
)#
timing[ , package := factor(package, levels = c('qmf', 'ours', 'ours on Allstate cluster')) ]#
#
ggplot(timing, aes(x = datasets, y = times, fill = package)) +#
geom_bar(stat = 'identity', position = 'dodge')
ggplot(timing, aes(x = datasets, y = times, fill = package)) +#
geom_bar(stat = 'identity', position = 'dodge') +#
theme_bw()
ggplot(timing, aes(x = datasets, y = times, fill = package)) +#
geom_bar(stat = 'identity', position = 'dodge') +#
labs(title = 'Runtime Benchmarks') +#
scale_color_fivethirtyeight() +#
theme_fivethirtyeight()
library(ggplot2)#
library(ggthemes)#
library(data.table)#
#
timing <- data.table(#
    datasets = c('Last.fm', 'Last.fm', 'Last.fm', 'Amazon Product', 'Amazon Product', 'Amazon Product'),#
    times = c(4.8, 2.8, 0.5, 82.2, 34.4, 6.5), #
    package = c('qmf', 'ours', 'ours on Allstate cluster', 'qmf', 'ours', 'ours on Allstate cluster')#
)#
timing[ , package := factor(package, levels = c('qmf', 'ours', 'ours on Allstate cluster')) ]#
#
ggplot(timing, aes(x = datasets, y = times, fill = package)) +#
geom_bar(stat = 'identity', position = 'dodge') +#
labs(title = 'Runtime Benchmarks') +#
scale_color_fivethirtyeight() +#
theme_fivethirtyeight()
ggplot(timing, aes(x = datasets, y = times, fill = package)) +#
geom_bar(stat = 'identity', position = 'dodge') +#
labs(title = 'Runtime Benchmarks') +#
scale_fill_fivethirtyeight() +#
theme_fivethirtyeight()
last_fm <- rep('Last.fm Music Preference \n(358,868 users, 292,364 items)', 3)#
amazon  <- rep('Amazon Product Ratings\n(21,176,522 users, 9,874,211 items)', 3)#
dataset <- c(last_fm, amazon)#
package <- c('qmf (8 cores)', 'ours (8 cores)', 'ours on Allstate cluster (192 cores)')#
timing <- data.table(#
    datasets = dataset,#
    times = c(4.8, 2.8, 0.5, 82.2, 34.4, 6.5), #
    packages = rep(package, 2)#
)#
timing[ , package := factor(package, levels = c('qmf', 'ours', 'ours on Allstate cluster')) ]#
#
ggplot(timing, aes(x = datasets, y = times, fill = packages)) +#
geom_bar(stat = 'identity', position = 'dodge') +#
labs(title = 'Runtime Benchmarks') +#
scale_fill_fivethirtyeight() +#
theme_fivethirtyeight()
last_fm <- rep('Last.fm Music Preference \n(358,868 users, 292,364 items)', 3)#
amazon  <- rep('Amazon Product Ratings\n(21,176,522 users, 9,874,211 items)', 3)#
dataset <- c(last_fm, amazon)#
package <- c('qmf (8 cores)', 'ours (8 cores)', 'ours on Allstate cluster (192 cores)')#
timing <- data.table(#
    datasets = dataset,#
    times = c(4.8, 2.8, 0.5, 82.2, 34.4, 6.5), #
    packages = rep(package, 2)#
)#
timing[ , package := factor(package, levels = package) ]#
#
ggplot(timing, aes(x = datasets, y = times, fill = packages)) +#
geom_bar(stat = 'identity', position = 'dodge') +#
labs(title = 'Runtime Benchmarks') +#
scale_fill_fivethirtyeight() +#
theme_fivethirtyeight()
last_fm <- rep('Last.fm Music Preference \n(358,868 users, 292,364 items)', 3)#
amazon  <- rep('Amazon Product Ratings\n(21,176,522 users, 9,874,211 items)', 3)#
dataset <- c(last_fm, amazon)#
package <- c('qmf (8 cores)', 'ours (8 cores)', 'ours on Allstate cluster (192 cores)')#
timing <- data.table(#
    datasets = dataset,#
    times = c(4.8, 2.8, 0.5, 82.2, 34.4, 6.5), #
    packages = rep(package, 2)#
)#
timing[ , packages := factor(packages, levels = package) ]#
#
ggplot(timing, aes(x = datasets, y = times, fill = packages)) +#
geom_bar(stat = 'identity', position = 'dodge') +#
labs(title = 'Runtime Benchmarks') +#
scale_fill_fivethirtyeight() +#
theme_fivethirtyeight()
ggplot(timing, aes(x = datasets, y = times, fill = packages)) +#
geom_bar(stat = 'identity', position = 'dodge') +#
labs(title = 'Runtime Benchmarks') +#
scale_fill_fivethirtyeight() +#
theme_fivethirtyeight() +#
theme(axis.text.x = element_text(size = 16))
ggplot(timing, aes(x = datasets, y = times, fill = packages)) +#
geom_bar(stat = 'identity', position = 'dodge') +#
labs(title = 'Runtime Benchmarks') +#
scale_fill_fivethirtyeight() +#
theme_fivethirtyeight() +#
theme(axis.text.x = element_text(size = 10))
ggplot(timing, aes(x = datasets, y = times, fill = packages)) +#
geom_bar(stat = 'identity', position = 'dodge') +#
labs(title = 'Runtime Benchmarks') +#
scale_fill_fivethirtyeight() +#
theme_fivethirtyeight() +#
theme(axis.text.x = element_text(size = 12))
ggsave('benchmark.png')
ggplot(timing, aes(x = datasets, y = times, fill = packages)) +#
geom_bar(stat = 'identity', position = 'dodge') +#
labs(title = 'Runtime Benchmarks') +#
scale_fill_fivethirtyeight() +#
theme_fivethirtyeight() +#
theme(axis.text.x = element_text(size = 12))#
#
ggsave('benchmark.png')
ggplot(timing, aes(x = datasets, y = times, fill = packages)) +#
geom_bar(stat = 'identity', position = 'dodge') +#
labs(title = 'Runtime Benchmarks') +#
scale_fill_fivethirtyeight() +#
theme_fivethirtyeight() +#
theme(axis.text.x = element_text(size = 12)) +#
coord_flip()
last_fm <- rep('Last.fm Music Preference \n(358,868 users, 292,364 items)', 3)#
amazon  <- rep('Amazon Product Ratings\n(21,176,522 users, 9,874,211 items)', 3)#
dataset <- c(amazon, last_fm)#
package <- c('qmf (8 cores)', 'ours (8 cores)', 'ours on Allstate cluster (192 cores)')#
timing <- data.table(#
    datasets = dataset,#
    times = c(82.2, 34.4, 6.5, 4.8, 2.8, 0.5), #
    packages = rep(package, 2)#
)#
timing[ , packages := factor(packages, levels = package) ]#
#
ggplot(timing, aes(x = datasets, y = times, fill = packages)) +#
geom_bar(stat = 'identity', position = 'dodge') +#
labs(title = 'Runtime Benchmarks') +#
scale_fill_fivethirtyeight() +#
theme_fivethirtyeight() +#
theme(axis.text.x = element_text(size = 12)) +#
coord_flip()
last_fm <- rep('Last.fm Music Preference \n(358,868 users, 292,364 items)', 3)#
amazon  <- rep('Amazon Product Ratings\n(21,176,522 users, 9,874,211 items)', 3)#
dataset <- c(amazon, last_fm)#
package <- c('ours on Allstate cluster (192 cores)', 'ours (8 cores)', 'qmf (8 cores)')#
timing <- data.table(#
    datasets = dataset,#
    times = c(82.2, 34.4, 6.5, 4.8, 2.8, 0.5), #
    packages = rep(package, 2)#
)#
timing[ , packages := factor(packages, levels = package) ]#
#
ggplot(timing, aes(x = datasets, y = times, fill = packages)) +#
geom_bar(stat = 'identity', position = 'dodge') +#
labs(title = 'Runtime Benchmarks') +#
scale_fill_fivethirtyeight() +#
theme_fivethirtyeight() +#
theme(axis.text.x = element_text(size = 12)) +#
coord_flip()
last_fm <- rep('Last.fm Music Preference \n(358,868 users, 292,364 items)', 3)#
amazon  <- rep('Amazon Product Ratings\n(21,176,522 users, 9,874,211 items)', 3)#
dataset <- c(last_fm, amazon)#
package <- c('ours on Allstate cluster (192 cores)', 'ours (8 cores)', 'qmf (8 cores)')#
timing <- data.table(#
    datasets = dataset,#
    times = c(82.2, 34.4, 6.5, 4.8, 2.8, 0.5), #
    packages = rep(package, 2)#
)#
timing[ , packages := factor(packages, levels = package) ]#
#
ggplot(timing, aes(x = datasets, y = times, fill = packages)) +#
geom_bar(stat = 'identity', position = 'dodge') +#
labs(title = 'Runtime Benchmarks') +#
scale_fill_fivethirtyeight() +#
theme_fivethirtyeight() +#
theme(axis.text.x = element_text(size = 12)) +#
coord_flip()
last_fm <- rep('Last.fm Music Preference \n(358,868 users, 292,364 items)', 3)#
amazon  <- rep('Amazon Product Ratings\n(21,176,522 users, 9,874,211 items)', 3)#
dataset <- c(amazon, last_fm)#
package <- c('ours on Allstate cluster (192 cores)', 'ours (8 cores)', 'qmf (8 cores)')#
timing <- data.table(#
    datasets = dataset,#
    times = c(82.2, 34.4, 6.5, 4.8, 2.8, 0.5), #
    packages = rep(package, 2)#
)#
timing[ , packages := factor(packages, levels = package) ]#
#
ggplot(timing, aes(x = datasets, y = times, fill = packages)) +#
geom_bar(stat = 'identity', position = 'dodge') +#
labs(title = 'Runtime Benchmarks') +#
scale_fill_fivethirtyeight() +#
theme_fivethirtyeight() +#
theme(axis.text.x = element_text(size = 12)) +#
coord_flip()
last_fm <- rep('Last.fm Music Preference \n(358,868 users, 292,364 items)', 3)#
amazon  <- rep('Amazon Product Ratings\n(21,176,522 users, 9,874,211 items)', 3)#
dataset <- c(amazon, last_fm)#
package <- c('qmf (8 cores)', 'ours (8 cores)', 'ours on Allstate cluster (192 cores)', )#
timing <- data.table(#
    datasets = dataset,#
    times = c(82.2, 34.4, 6.5, 4.8, 2.8, 0.5), #
    packages = rep(package, 2)#
)#
timing[ , packages := factor(packages, levels = package) ]#
#
ggplot(timing, aes(x = datasets, y = times, fill = packages)) +#
geom_bar(stat = 'identity', position = 'dodge') +#
labs(title = 'Runtime Benchmarks') +#
scale_fill_fivethirtyeight() +#
theme_fivethirtyeight() +#
theme(axis.text.x = element_text(size = 12)) +#
coord_flip()
last_fm <- rep('Last.fm Music Preference \n(358,868 users, 292,364 items)', 3)#
amazon  <- rep('Amazon Product Ratings\n(21,176,522 users, 9,874,211 items)', 3)#
dataset <- c(amazon, last_fm)#
package <- c('qmf (8 cores)', 'ours (8 cores)', 'ours on Allstate cluster (192 cores)')#
timing <- data.table(#
    datasets = dataset,#
    times = c(82.2, 34.4, 6.5, 4.8, 2.8, 0.5), #
    packages = rep(package, 2)#
)#
timing[ , packages := factor(packages, levels = package) ]#
#
ggplot(timing, aes(x = datasets, y = times, fill = packages)) +#
geom_bar(stat = 'identity', position = 'dodge') +#
labs(title = 'Runtime Benchmarks') +#
scale_fill_fivethirtyeight() +#
theme_fivethirtyeight() +#
theme(axis.text.x = element_text(size = 12)) +#
coord_flip()
ggsave('benchmark.png')
ggsave('benchmark.png', width = 7, height = 7)
ggsave('benchmark.png', width = 10, height = 10)
raw <- fread('rawdata.csv')#
#
# remove abnormality,#
# Passenger count should be greater than 0, #
# Only keep rows with trip distance, Extra,#
# MTA_tax, Tip_amount, and Tolls_amount >= 0#
# From the source below#
# http://www.nyc.gov/html/tlc/html/passenger/taxicab_rate.shtml#
# the minimum fare amount should be >= 2.5#
raw <- raw[#
    Passenger_count > 0 &#
    Fare_amount >= 2.5 &#
    Trip_distance > 0 &#
    Extra >= 0 &#
    MTA_tax >= 0 &#
    Tip_amount >= 0 &#
    Tolls_amount >= 0 &#
    improvement_surcharge >= 0#
,]#
#
# we re-computed the total amount ourselves by adding up all the amount, tax#
# instead of using the Total_amount column;#
# to test whether two floats are equal use whether they are closer than#
# a small value, rather than whether the two are exactly equal#
# http://stackoverflow.com/questions/2769510/numeric-comparison-difficulty-in-r#
raw[, total := Fare_amount + MTA_tax + Tip_amount + improvement_surcharge + Extra]#
raw <- raw[abs(total - Total_amount) <= 1e-8, ]#
#
# there are only 22 observations with ratecodeId = 6 (group ride),#
# remove them to only consider individual ride#
raw <- raw[RateCodeID != 6,]#
#
# from the data dictionary, if trip_type = 1, there will be#
# an improvement surcharge of 0.3, else improvement surcharge#
# should be 0#
raw <- raw[#
    (Trip_type == 1 & improvement_surcharge == 0.3) |#
    (Trip_type != 1 & improvement_surcharge == 0)#
,]#
#
# generate trip duration time,#
# and remove the rows with same pickup and drop time (0 duration time)#
raw[, lpep_pickup_datetime := ymd_hms(lpep_pickup_datetime)]#
raw[, Lpep_dropoff_datetime := ymd_hms(Lpep_dropoff_datetime)]#
raw[, pickup_hr := hour(Lpep_dropoff_datetime)]#
raw[, dropoff_hr := hour(Lpep_dropoff_datetime)]#
raw[, duration_min := as.numeric(Lpep_dropoff_datetime - #
                                 lpep_pickup_datetime, units = 'mins')]#
raw <- raw[duration_min > 0,]#
#
# for the pick up hour, generate factors#
# early Peak hour: 7-9#
# late Peak hour: 4-10PM#
# other hours#
# since this may affect tipping behavior#
raw[, hourtype := ifelse(pickup_hr %in% 7:9, 'earlypeakhr', #
                      ifelse(pickup_hr %in% 16:22, 'latepeakhr','Others')) ]#
raw[, hourtype := as.factor(hourtype)]#
#
# create speed (miles per minute) column #
# and remove the rows with infeasible speed;#
# a reasonable speed for a car is around 220 miles/hour = 3.66 mpm#
# and cars that are going above 55mph (0.916 mpm) should be getting#
# a speed ticket#
raw[, speed_mpm := Trip_distance / duration_min]#
raw <- raw[speed_mpm < 3.66,]#
raw[, speed_ticket := as.factor( ifelse(speed_mpm > 0.916, 1, 0) ) ]#
#
# trip direction#
raw[, northsouth := ifelse(Dropoff_latitude - Pickup_latitude > 0, 'North','South')]#
raw[, eastwest := ifelse(Dropoff_longitude - Pickup_longitude > 0, 'East','West')]#
raw[, northsouth := as.factor(northsouth)]#
raw[, eastwest := as.factor(eastwest)]#
#
# create an indicator for classification model predicting whether a person#
# will give a tip or not and tip percentage for predicting the amount of#
# tip a person will give#
raw[, tipindicator := as.factor( ifelse(Tip_amount > 0, 1, 0) )]#
raw[, tip_percentage := Tip_amount / total]#
#
# remove unnecessary columns,#
# remove the Ehail_fee, since it's simply a bunch of NAs#
# improvement_surcharge since it's dependent of trip type;#
# Tolls_amount, since the value is all 0#
# remove Store_and_fwd_flag, VendorID since it simply indicates#
# how the data was recorded#
raw[, `:=`(Ehail_fee = NULL,#
           Total_amount = NULL,#
           Tolls_amount = NULL, #
           improvement_surcharge = NULL,#
           lpep_pickup_datetime = NULL,#
           Lpep_dropoff_datetime = NULL,#
           pickup_hr = NULL,#
           dropoff_hr = NULL,#
           Store_and_fwd_flag = NULL,#
           VendorID = NULL,#
           Pickup_longitude = NULL,#
           Pickup_latitude = NULL,#
           Dropoff_longitude = NULL,#
           Dropoff_latitude = NULL)]#
#
raw[, `:=`(RateCodeID = as.factor(RateCodeID),#
           Payment_type = as.factor(Payment_type),#
           Trip_type = as.factor(Trip_type)) ]
library(DT)#
library(lsa)#
library(caret)#
library(shiny)#
library(stringr)#
library(data.table)#
library(shinythemes)#
library(shinydashboard)#
setwd('/Users/ethen/sports/presentation')#
#
# define global parameters#
FILE_PATH <- 'box2015.csv'#
POSITION_PATH <- 'positions.csv'#
#
# include only player who has above #
# a certain number of minutes per game#
MINUTES_THRESHOLD <- 10#
#
# parameters for kmeans clustering#
seed <- 12345#
N_START <- 10#
ITER_MAX <- 100#
#
position <- fread(POSITION_PATH)#
position <- unique(position)#
setnames(position, c('player', 'position'))#
#
# --------------------------------------------------------------------------------------#
# preprocessing#
preprocess <- function(box_data, minutes_threshold) {#
    box_data <- box_data[MINUTES_PLAYED > minutes_threshold,]#
#
    # extract possibly useful columns that are normalized by minutes.#
    # turnovers and personal fouls were not indicative in clusters result,#
    # thus we did not include them;#
    # for the three pointers, two pointers and free throws include the #
    # raw attempt count and basket made instead of turning them into#
    # percentages (when turned into percentages, the cluster result was sub-optimal)#
    box_data[, ('Points_Per_Minute') := TOTAL_POINTS / MINUTES_PLAYED]#
    box_data[, ('Assists_Per_Minute') := ASSISTS / MINUTES_PLAYED]#
    box_data[, ('Rebounds_Per_Minute') := REBOUNDS / MINUTES_PLAYED]#
    box_data[, ('Steals_Per_Minute') := STEALS / MINUTES_PLAYED]#
    box_data[, ('Blocks_Per_Minute') := BLOCKED_SHOTS / MINUTES_PLAYED]#
    box_data[, ('Two_Points_Att') := FIELD_GOALS_ATT - THREE_POINT_ATT]#
    box_data[, ('Two_Points_Made') := FIELD_GOALS_MADE - THREE_POINT_MADE]#
#
    # change names to be snake case instead of the all caps#
    old_names <- c('PLAYER', 'FREE_THROWS_ATT', 'THREE_POINT_ATT', #
                   'FREE_THROWS_MADE', 'THREE_POINT_MADE')#
    new_names <- c('Player', 'Free_Throw_Att', 'Three_Point_Att', #
                   'Free_Throw_Made', 'Three_Point_Made')#
    setnames(box_data, old_names, new_names)#
    # all the features that will be in the dataset#
    retain_cols <- c('Blocks_Per_Minute',#
                     'Points_Per_Minute', 'Assists_Per_Minute',#
                     'Rebounds_Per_Minute', 'Steals_Per_Minute',#
                     'Two_Points_Made', 'Two_Points_Att', new_names)#
    box_data <- box_data[, retain_cols, with = FALSE]#
#
    # replace NAs with 0#
    for ( j in seq_len(ncol(box_data)) ) {#
        set(box_data, which( is.na(box_data[[j]]) ), j, 0)#
    }#
    return(box_data)#
}#
box_data <- fread(FILE_PATH)#
box_data <- preprocess(box_data, MINUTES_THRESHOLD)#
# clustering kmeans#
# exclude the player information and standardize the data#
# prior to performing cluster#
player <- box_data[['Player']]#
box_data[, Player := NULL]#
standardize <- preProcess(box_data, method = c('center', 'scale'))#
box_data_scaled <- predict(standardize, box_data)#
#
# we decided to use 6 clusters, not because there is a clear elbow,#
# but because the interpretation made more sense#
set.seed(SEED)#
fit <- kmeans(box_data_scaled, centers = 6, iter.max = ITER_MAX, nstart = N_START)#
# cluster interpretation#
# 1. facilitator, distributors#
# 2. bad games#
# 3. defensive players#
# 4. three point shooters#
# 5. power forward/centers#
# 6. all stars that's carrying their team !!!!!!#
# --------------------------------------------------------------------------------------#
# obtain players that have similar play styles (not performance)#
#
# put the player names and cluster assignment to each row #
# aggregate players to each cluster#
# i.e. how many times did each player appear in each cluster#
box_data_scaled[, player := player]#
box_data_scaled[, cluster := fit$cluster]#
aggregation <- box_data_scaled[, .(counts = .N), by = .(cluster, player)]#
#
# convert to wide format#
player_cluster <- dcast(aggregation, player ~ cluster, #
                        value.var = 'counts', fill = 0)#
player <- player_cluster[['player']]#
player_cluster[, player := NULL]#
#
# normalized & standardize#
normalized <- as.matrix(player_cluster) / rowSums(player_cluster)#
standardize <- preProcess(normalized, method = c('center', 'scale'))#
normalized_scaled <- predict(standardize, normalized)#
#
# compute pairwise cosine distance#
distance <- lsa::cosine(t(normalized_scaled))#
compute_score <- function(distance, query) {#
    # given the pairwise distance and the index of a player#
    # compute the similar play style score#
#
    # convert from cosine distance to angle #
    # (acos gives the radian .........................)#
    cosine_distance <- acos(distance[query, ]) * 180 / pi#
#
    # convert the cosine angle (0 ~ 180) to a single normalized score#
    # ranging from 0 to 100#
    # and cut the decimal places to prevent cluttering the page#
    score <- ( (180 - cosine_distance) / 180 ) * 100#
    score <- round(score, 1)#
    dt_score <- data.table(score = score, player = player)#
    return(dt_score)#
}#
# example#
# query <- which(player == 'Stephen Curry')#
# result <- compute_score(distance, query)#
# --------------------------------------------------------------------------------------#
# dashboard#
#
body <- dashboardBody(#
    # changing dashboard background color to white#
    # https://github.com/rstudio/shinydashboard/issues/31#
    includeCSS('www/custom.css'),#
    tabItems(#
        tabItem(tabName = 'DashBoard',#
            fluidPage(#
                titlePanel('Similarity-O-Meter'),#
                sidebarLayout(#
                    sidebarPanel(#
                        helpText('Find Players with Similar Playstyle'),#
                        hr(),#
                        selectInput(inputId = 'choose_player',#
                                    label = 'Choose Player:',#
                                    choices = player),#
                        br(),#
                        actionButton(inputId = 'start_analysis',#
                                     label = 'Start Analysis',#
                                     style = 'color: #fff; background-color: #337ab7; border-color: #2e6da4')#
                    ),                   #
                    mainPanel(#
                        dataTableOutput(outputId = 'output_table')#
                    )#
                )#
            )#
        )#
    )#
)#
ui <- dashboardPage(#
    dashboardHeader(title = 'Sports Analytics'),#
    dashboardSidebar(#
        sidebarMenu(#
            menuItem('DashBoard', tabName = 'DashBoard', icon = icon('dashboard'))#
        )#
    ),#
    body#
)#
server <- function(input, output) {#
    output$output_table <- renderDataTable({#
        # the output should only be dependent on #
        # the action button#
        input$start_analysis#
#
        # compute the most similar players, include their#
        # positions sorted by the normalized score (scale 0 ~ 100)#
        # and remove itself from the result#
        query <- which(player == isolate(input$choose_player))#
        result <- compute_score(distance, query)#
        result <- merge(result, position)[order(-score),]#
        result <- result[2:nrow(result), ]#
        return(result)#
    })#
}#
#
shinyApp(ui, server)
