---
title: "Data Mining HW 3"
author: "Annie Didier"
date: "January 23, 2017"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

1. 
a)
```{r}
X = matrix(c(1,3,5,0,1, 2,4,4,2,3, 3,5,3,4,5), nrow=5)
x_tran_x = t(X) %*% X
x_x_tran = X %*% t(X)
x_tran_x
x_x_tran
```

b)
```{r}
ei_x_tran_x = eigen(x_tran_x)
ei_x_x_tran = eigen(x_x_tran)
ei_x_tran_x
ei_x_x_tran
```

c)
```{r}
A = ei_x_tran_x$vectors%*%diag(ei_x_tran_x$values)%*% t(ei_x_tran_x$vectors)
A
```
The output is the same as 2a. 

d)
```{r}
svd_x = svd(X)
#Compare to b
svd_x$v
ei_x_tran_x$vectors
svd_x$u
ei_x_x_tran$vectors
(svd_x$d)^2
(ei_x_tran_x$values)
ei_x_x_tran$values
```
We can see that V gives the eigenvectors of X'X and that the first two columns of U correspond to the first two eigenvectors of XX' since the rank of X is 2.  

e)
```{r}
ULV = svd_x$u %*% diag(svd_x$d) %*% t(svd_x$v)
ULV
X
```

f)
```{r}
#set the third value to 0 since X has rank 2
svd_x_rank2 = svd_x$d[1:2] 
#set the smallest eigenvalue to 0 to do the 1-d projection
svd_x_oned = svd_x$d
svd_x_oned[2:3] = 0
svd_u_one = svd_x$u
svd_u_one[,2:3] = 0
svd_v_one = svd_x$v
svd_v_one[,2:3] = 0
xhat = svd_u_one %*% diag(svd_x_oned) %*% t(svd_v_one)
xhat
```
xhat is very close to x, so the 1D estimate is a good approximation. 

g)
```{r}
ssxhat = sum(xhat^2)
ssxhat
sum(svd_x$d^2)
```
The Frobenius norm of xhat is the same as the sum of squares of the singular values. 

h)
```{r}
SSE = sum((X-xhat)^2)
SSE
svd_x$d[1]+svd_x$d[2]
```
The sum of squared errors is a good approximation of the sum of the two eigenvalues. 

i) 
```{r}
energy = svd_x_oned^2/(sum(svd_x$d^2))
energy
```
2.
```{r}
theater = read.csv("theater.csv")
theater = theater[, -c(3,5,7,10)]
```

3. 
```{r}
music = read.csv("music.csv")
```